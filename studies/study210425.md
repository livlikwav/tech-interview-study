# 210425 일

- 참가자
  - @livlikwav
  - @hoyeon94
  - @coloryourlife
- 진행 순서
  - 근황 토크
  - ML 관련 질문들
  - 링크 공유

## ML 관련 질문들 정리

- [210425 일](#210425-일)
  - [ML 관련 질문들 정리](#ml-관련-질문들-정리)
    - [dataset을 위한 VCS가 있나?](#dataset을-위한-vcs가-있나)
    - [Annotation과 labeling의 차이는?](#annotation과-labeling의-차이는)
    - [fine-tuning이란?](#fine-tuning이란)
    - [BERT, GPT와 같이 유명한 모델은 다 알아야 하나?](#bert-gpt와-같이-유명한-모델은-다-알아야-하나)
    - [mlflow는 뭔가?](#mlflow는-뭔가)
    - [모델 저장은 보통 어떻게 하나?](#모델-저장은-보통-어떻게-하나)
    - [pkl은 뭐지?](#pkl은-뭐지)
    - [모델 저장 관련해서 개선점은 없나?](#모델-저장-관련해서-개선점은-없나)
    - [pytorch와 tensorflow의 차이는? 왜 pytorch를 많이 쓰나?](#pytorch와-tensorflow의-차이는-왜-pytorch를-많이-쓰나)
    - [TFLite 간략한 설명?](#tflite-간략한-설명)
    - [HPO할 때 하이퍼파라미터가 정확히 무엇인가?](#hpo할-때-하이퍼파라미터가-정확히-무엇인가)
    - [checkpoint와 학습이 끝난 모델의 차이는 무엇인가?](#checkpoint와-학습이-끝난-모델의-차이는-무엇인가)
    - [모델 서빙하는 간단한 flask 서버 만들어 봤었다하지 않았었나?](#모델-서빙하는-간단한-flask-서버-만들어-봤었다하지-않았었나)
  - [링크 공유](#링크-공유)

### dataset을 위한 VCS가 있나?

hoyeon94: pachyderm을 사용해봤다. 거기에 minio(object DB)를 붙여서 사용했었다.  

pachyderm이 minio에 있는 데이터를 관리해주는 느낌이다.

저장해두고, 데이터 셋을 불러올 때는, branch를 지정하고 그 데이터셋 마지막 commit을 불러오는 식으로 사용한다.  

### Annotation과 labeling의 차이는?

(검색 결과)

Labeling이 더 큰 범위의 개념인 것 같다.

Annotation은 labeling technique 중 하나이고, 특히 computer vision에서 쓰이는 것 같다.

### fine-tuning이란?

(검색 결과)

fine tuning이란 사전 학습 모델을 기반으로 새로운 목적(질의응답, 번역등)을 위해,

이미 학습된 weight나 bias를 미세하게 조정하는 과정을 말한다.

이 기법이 전이 학습에 사용되곤 한다.

완전히 랜덤한 파라미터로 학습을 시작하는 것이 아닌, 큰 데이터로 pre-trained된 model을 사용하는 것이다.

### BERT, GPT와 같이 유명한 모델은 다 알아야 하나?

물론 다 알면 좋겠지만, 보통 머신러닝도 분야별로 나뉘기 때문에, 자신의 전문분야를 잘 알고 있는 경우가 많다.

### mlflow는 뭔가?

많이는 모르고, mlflow tracking 기능을 모니터링에 사용해봤었다.

> MLflow Tracking component is an API and UI for logging parameters, code versions, metrics, and output files when running your machine learning code and for later visualizing the results. MLflow Tracking lets you log and query experiments.

### 모델 저장은 보통 어떻게 하나?

모델 저장도 어려운 문제인데, 프레임워크마다 다르다.

프레임워크라고 하면 사실 크게 2가지를 말한다. → pytorch, tensorflow

tensorflow에서 간단한 모델의 경우는 모델 구조까지 그대로 저장 가능했던 것 같다(하지만 pytorch는 쉽지 않았음).

하지만 복잡한 모델의 경우에는, 두 프레임워크 모두 저장이 힘들어, 저장시 그냥 소스코드를 같이 줘야 했었음.

정리하자면... 총 2가지를 저장해야함.

- 학습된 weights
- 모델 구조 저장된 파일 혹은 소스코드

그리고 학습이 끝나고 난 모델도 위와 같이 저장할 수 있고,

혹은 pkl 확장자 같은 파일로 저장할 수 있음.

### pkl은 뭐지?

파이썬의 직렬화 라이브러리이다. 파이썬 객체를 그대로 저장하고 불러오고 할 수 있나보다. 이걸로 모델 객체를 그대로 저장해버리나 보다.

> A PKL file is a file created by pickle, a Python module that enabless objects to be serialized to files on disk and deserialized back into the program at runtime. It contains a byte stream that represents the objects.

### 모델 저장 관련해서 개선점은 없나?

두 프레임워크 모두 구조를 그대로 저장하는 것에 한계가 있어서, ONNX 같은 것을 사용하기도 한다.

> The Open Neural Network Exchange is an open-source artificial intelligence ecosystem. Interoperability. Develop in your preferred framework without worrying about downstream inferencing implications. ONNX enables you to use your preferred framework with your chosen inference engine.

ONNX 형식이 있고, 이걸로 저장하고, 이걸로 배포를 할 수 있음 → 프레임워크에 바로 태울 수 있음 ONNX 형식을.

### pytorch와 tensorflow의 차이는? 왜 pytorch를 많이 쓰나?

tensorflow 1.x가 좀 별로였다. 현재는 tensorflow 2.x가 나오고 keras도 나와서 좀 낫다.

pytorch가 코드 가독성이 훨씬 좋다. 사용도 편리했다.

그래서 [https://paperswithcode.com/](https://paperswithcode.com/) 참고해봐도, 높은 랭킹의 예제 코드들은 거의 대부분 pytorch인 경우가 많다.

하지만 tensorflow도 무시할 수 없는게,  ecosystem이 빵빵하다. 실제 서비스하기에 더 편리할 수 있다.

예를 들어, TFServing, TFJob, TFLite등이 있다.

### TFLite 간략한 설명?

livlikwav: 소마 프로젝트할 때, 협업했던 팀원이 tflite 사용해서 라즈베리파이에 모델을 올렸었다.

혹시 tflite가 어떤식으로 최적화해주는 것인가?

hoyeon94: floating 연산이 비싼데, 이러한 연산들을 아예 안한다던지 한다.

> Use the TensorFlow Lite Converter to convert a TensorFlow model into a TensorFlow Lite model. During conversion, you can apply optimizations such as quantization to reduce model size and latency with minimal or no loss in accuracy. By default, all models don't contain metadata.

> The TensorFlow Lite converter takes a TensorFlow model and generates a TensorFlow Lite model (an optimized FlatBuffer format identified by the .tflite file extension).

### HPO할 때 하이퍼파라미터가 정확히 무엇인가?

Hyperparameter optimization

머신러닝에서 말하는 파라미터는 크게 2가지이다.

- 파라미터
    - 학습하면서 바뀌는 알아서 값들. weight와 같은
- 하이퍼파라미터
    - 사용자가 넣은 모든 변수들
    - 숫자값 외에 optimizer 종류(SGD, adagrad ...) 같은 것들도 포함한다.

### checkpoint와 학습이 끝난 모델의 차이는 무엇인가?

비슷하긴 한데, checkpoint 같은 경우에는 학습에 관한 메타데이터도 저장된다(저장할 때 몇 epoch였는지... 와 같은).

### 모델 서빙하는 간단한 flask 서버 만들어 봤었다하지 않았었나?

web server와 inference server 두고 사용했었다. 검색하면 나오는 예제코드 거의 따라했다.

(검색 결과, [참고](https://guillaumegenthial.github.io/serving.html))

```python
# 디렉토리 구조
serve.py
app.py
model/
    __init__.py
    base_model.py
    ner_model.py
    config.py
    ...
```

```python
# serve.py
from model.ner_model import NERModel
from model.config import Config
from model.utils import align_data


def get_model_api():
    """Returns lambda function for api"""
    # 1. initialize model once and for all and reload weights
    config = Config()
    model  = NERModel(config)
    model.build()
    model.restore_session("results/crf/model.weights/")

    def model_api(input_data):
        # 2. process input with simple tokenization and no punctuation
        punc = [",", "?", ".", ":", ";", "!", "(", ")", "[", "]"]
        s = "".join(c for c in input_data if c not in punc)
        words_raw = s.strip().split(" ")
        # 3. call model predict function
        preds = model.predict(words_raw)
        # 4. process the output
        output_data = align_data({"input": words_raw, "output": preds})
        # 5. return the output for the api
        return output_data

    return model_api
```

```python
# app.py
from flask import Flask, request, jsonify
from flask_cors import CORS
from serve import get_model_api  # see part 1.

app = Flask(__name__)
CORS(app) # needed for cross-domain requests, allow everything by default
model_api = get_model_api()

# API route
@app.route('/api', methods=['POST'])
def api():
    input_data = request.json
    output_data = model_api(input_data)
    response = jsonify(output_data)
    return response
```

이와 같은 코드로 간단한 flask를 통한 서빙을 수행했던 것 같다.

## 링크 공유

- [Software 2.0](https://karpathy.medium.com/software-2-0-a64152b37c35)
  - 2017년 작성된 글이지만, 많은 영감을 준다.
- [챗봇 1만 개의 모델 서빙하기: AI 서비스 어디까지 해봤니(DEVIEW 2020)](https://tv.naver.com/v/11212632)
  - AI로 돈을 벌기 위한 현실적인 고민을 어렴풋이 감을 잡을 수 있다(다 이해하지는 못함).
